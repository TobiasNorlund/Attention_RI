# Word Embeddings applied to Text Classification
Word embeddings such as word2vec, GloVe and other Distributional Semantic Models have in the latest past been succesfully applied to various Natural Language Processing tasks. Many such tasks implies some kind of classification, for example sentiment analysis and text categorization.

This repository constitutes the main code of my Master's Thesis, where I compare the Random Indexing [1] embedding to other popular embeddings using different models and datasets. I also try to modify the embeddings to boost the performance.

## References

[1] Sahlgren, M.,  [i]An Introduction to Random Indexing[/i], 2005
